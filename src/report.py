#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
KVAS report + Telegram message generator.

Inputs:
- dist/state.json (produced by src/build.py)
- dist/stats.json (history; appended here)

Outputs:
- dist/report.md
- dist/tg_message.txt
- dist/tg_alert.txt (only when WARNING/ERROR; otherwise deleted)

Guarantees:
- from __future__ import annotations is at the top (no syntax traps)
- report.md is regenerated every run
- Telegram follows approved templates (ERROR / WARNING / OK)
"""

from __future__ import annotations

import json
import hashlib
from dataclasses import dataclass
from datetime import datetime, timezone, timedelta
from pathlib import Path
from typing import Dict, List, Tuple, Optional


ROOT = Path(__file__).resolve().parents[1]
DIST = ROOT / "dist"

STATE_JSON = DIST / "state.json"
REPORT_MD = DIST / "report.md"
TG_MESSAGE = DIST / "tg_message.txt"
TG_ALERT = DIST / "tg_alert.txt"
STATS_JSON = DIST / "stats.json"

MSK = timezone(timedelta(hours=3))
MONTHS_RU = ["—è–Ω–≤","—Ñ–µ–≤","–º–∞—Ä","–∞–ø—Ä","–º–∞—è","–∏—é–Ω","–∏—é–ª","–∞–≤–≥","—Å–µ–Ω","–æ–∫—Ç","–Ω–æ—è","–¥–µ–∫"]


def load_json(path: Path, default):
    try:
        if not path.exists():
            return default
        return json.loads(path.read_text(encoding="utf-8"))
    except Exception:
        return default


def dump_json(path: Path, obj) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)
    path.write_text(json.dumps(obj, ensure_ascii=False, indent=2) + "\n", encoding="utf-8")


def fmt_build_time_msk(build_time_utc: str) -> str:
    # build_time_utc is ISO Z
    try:
        dt_utc = datetime.fromisoformat(build_time_utc.replace("Z", "+00:00")).astimezone(MSK)
    except Exception:
        dt_utc = datetime.now(timezone.utc).astimezone(MSK)
    m = MONTHS_RU[dt_utc.month - 1]
    return f"{dt_utc.day:02d} {m} {dt_utc.year}, {dt_utc:%H:%M} –ú–°–ö"


def fmt_tg_date_time(build_time_utc: str) -> Tuple[str, str]:
    try:
        dt = datetime.fromisoformat(build_time_utc.replace("Z", "+00:00")).astimezone(MSK)
    except Exception:
        dt = datetime.now(timezone.utc).astimezone(MSK)
    return dt.strftime("%d.%m.%Y"), dt.strftime("%H:%M:%S –ú–°–ö")


def diff_lists(prev: List[str], curr: List[str]) -> Tuple[List[str], List[str]]:
    p = set(prev or [])
    c = set(curr or [])
    added = sorted(c - p)
    removed = sorted(p - c)
    return added, removed


def short_hash(h: str) -> str:
    h = (h or "").strip()
    if len(h) < 10:
        return h or "‚Äî"
    return f"{h[:4]}‚Ä¶{h[-4:]}"


def pct(n: int, d: int) -> float:
    if d <= 0:
        return 0.0
    return round(n / d * 100.0, 1)


def limit_badge(p: float) -> str:
    if p >= 96.0:
        return "üî¥"
    if p >= 85.0:
        return "üü°"
    return "üü¢"


def status_emoji(status: str) -> str:
    s = (status or "").upper()
    if s == "OK":
        return "üü¢ –û–ö"
    if s == "EMPTY":
        return "üü° –ü–£–°–¢–û"
    if s == "FAIL":
        return "üî¥ –û–®–ò–ë–ö–ê"
    return "‚Äî"


def classify_severity(state: Dict) -> str:
    max_lines = int(state.get("max_lines", 3000))
    threshold = int(state.get("near_limit_threshold", 2900))
    total = int(state.get("final_total", 0))
    p = pct(total, max_lines)

    v2_fail = int(state.get("v2fly_fail", 0))
    bad = int(state.get("bad_output_lines", 0))
    trunc = int(state.get("truncated", 0))
    failed = state.get("failed_categories") or []
    empty = state.get("empty_categories") or []
    warns = state.get("warnings") or []

    if v2_fail > 0 or bad > 0 or trunc > 0 or p >= 96.0 or len(failed) > 0:
        return "–û–®–ò–ë–ö–ê"
    if len(empty) > 0 or len(warns) > 0 or total >= threshold or p >= 85.0:
        return "–ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–ï"
    return "–û–ö"


def append_stats(state: Dict) -> Tuple[List[Dict], Optional[Dict]]:
    """
    Append stats record and return (stats_list, prev_record).
    """
    stats = load_json(STATS_JSON, [])
    if not isinstance(stats, list):
        stats = []

    prev = stats[-1] if stats and isinstance(stats[-1], dict) else None

    rec = {
        "ts_utc": state.get("build_time_utc"),
        "total": int(state.get("final_total", 0)),
        "itdog": int(state.get("itdog_total", 0)),
        "v2fly": int(state.get("v2fly_total", 0)),
        "severity": classify_severity(state),
        "warnings": state.get("warnings", []),
        "failed_categories": state.get("failed_categories", []),
        "empty_categories": state.get("empty_categories", []),
    }
    stats.append(rec)
    stats = stats[-400:]
    dump_json(STATS_JSON, stats)
    return stats, prev


def trend_block(stats: List[Dict], prev: Optional[Dict], curr_total: int) -> Tuple[int, int, int, str]:
    """
    Returns: avg7, delta, deviation, eval_line
    """
    totals = [int(x.get("total", 0)) for x in stats[-7:] if isinstance(x, dict)]
    if not totals:
        avg7 = curr_total
    else:
        avg7 = int(round(sum(totals) / len(totals)))

    prev_total = int(prev.get("total", 0)) if isinstance(prev, dict) else None
    delta = (curr_total - prev_total) if prev_total is not None else 0
    deviation = curr_total - avg7

    # Eval line per approved wording
    if avg7 > 0 and curr_total >= avg7 * 2:
        eval_line = "üìà –†–æ—Å—Ç (–≤—ã—à–µ —Å—Ä–µ–¥–Ω–µ–≥–æ √ó2)"
    else:
        # stable if abs deviation small relative to avg
        tol = max(10, int(round(avg7 * 0.01)))
        if abs(deviation) <= tol:
            eval_line = "‚û° –°—Ç–∞–±–∏–ª—å–Ω–æ"
        elif deviation > 0:
            eval_line = "üìà –†–æ—Å—Ç"
        else:
            eval_line = "üìâ –ü–∞–¥–µ–Ω–∏–µ"

    return avg7, delta, deviation, eval_line


def format_report_md(state: Dict, stats: List[Dict], prev_rec: Optional[Dict]) -> str:
    build_time = fmt_build_time_msk(str(state.get("build_time_utc", "")))
    repo = str(state.get("repo", "unknown/unknown"))
    output = str(state.get("output", "dist/inside-kvas.lst"))
    max_lines = int(state.get("max_lines", 3000))
    threshold = int(state.get("near_limit_threshold", 2900))

    itdog_total = int(state.get("itdog_total", 0))
    v2_total = int(state.get("v2fly_total", 0))
    final_total = int(state.get("final_total", 0))

    trunc = int(state.get("truncated", 0))
    bad = int(state.get("bad_output_lines", 0))

    v2_ok = int(state.get("v2fly_ok", 0))
    v2_fail = int(state.get("v2fly_fail", 0))
    cats = state.get("v2fly_categories") or []
    empty_cats = state.get("empty_categories") or []
    failed_cats = state.get("failed_categories") or []
    warns = state.get("warnings") or []

    # diffs
    prev = state.get("prev") if isinstance(state.get("prev"), dict) else {}
    it_added, it_removed = diff_lists(prev.get("itdog_domains", []), state.get("itdog_domains", []))
    v2_added, v2_removed = diff_lists(prev.get("v2fly_extras", []), state.get("v2fly_extras", []))
    f_added, f_removed = diff_lists(prev.get("final_domains", []), state.get("final_domains", []))

    # limit
    p = pct(final_total, max_lines)
    near = "–ù–ï–¢"
    near_mark = "‚úÖ"
    if final_total >= threshold:
        near = "–î–ê"
        near_mark = "‚ö†Ô∏è"

    # warnings line
    warn_parts = []
    if len(failed_cats) > 0 or v2_fail > 0:
        warn_parts.append(f"{max(len(failed_cats), v2_fail)} –æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏")
    if len(empty_cats) > 0:
        warn_parts.append(f"{len(empty_cats)} –ø—É—Å—Ç–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è")
    if trunc > 0:
        warn_parts.append("–µ—Å—Ç—å –æ–±—Ä–µ–∑–∫–∞ –ø–æ –ª–∏–º–∏—Ç—É")
    if len(warns) > 0 and not warn_parts:
        warn_parts.append(f"{len(warns)} –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ")

    if warn_parts:
        warn_line = "‚ö†Ô∏è –ï—Å—Ç—å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è: " + ", ".join(warn_parts)
    else:
        warn_line = "‚úÖ –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π –Ω–µ—Ç"

    # critical problems
    critical = []
    if failed_cats:
        critical.append("üî¥ –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –Ω–µ —Å–∫–∞—á–∞–ª–∏—Å—å/–Ω–µ —Ä–∞—Å–ø–∞—Ä—Å–∏–ª–∏—Å—å: " + ", ".join(failed_cats))
    if trunc > 0:
        critical.append(f"üî¥ –û–±—Ä–µ–∑–∫–∞ –ø–æ –ª–∏–º–∏—Ç—É: –î–ê (–æ–±—Ä–µ–∑–∞–Ω–æ —Å—Ç—Ä–æ–∫: {trunc})")
    if bad > 0:
        critical.append(f"üî¥ –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ –≤ –≤—ã–≤–æ–¥–µ: {bad}")
    if p >= 96.0 or final_total >= threshold:
        critical.append(f"üî¥ –ü–æ—á—Ç–∏ –ª–∏–º–∏—Ç: {final_total} / {max_lines} ({p}%)")

    # v2fly table
    per_cat = state.get("v2fly_per_category") if isinstance(state.get("v2fly_per_category"), dict) else {}
    table_rows = []
    for c in cats:
        meta = per_cat.get(c, {}) if isinstance(per_cat.get(c, {}), dict) else {}
        table_rows.append(
            f"{c} | {int(meta.get('valid_domains',0))} | {int(meta.get('extras_added',0))} | "
            f"{int(meta.get('invalid_lines',0))} | {int(meta.get('skipped_directives',0))} | {status_emoji(str(meta.get('status','')))}"
        )
    if not table_rows:
        table_rows.append("‚Äî | 0 | 0 | 0 | 0 | ‚Äî")

    sha = short_hash(str(state.get("sha256_final", "")))

    # diagnostics
    intersection = len(set(state.get("itdog_domains", [])) & set(state.get("v2fly_extras", [])))
    reserve = max_lines - final_total
    risk = "–Ω–∏–∑–∫–∏–π üü¢" if p < 85.0 else ("—Å—Ä–µ–¥–Ω–∏–π üü°" if p < 96.0 else "–≤—ã—Å–æ–∫–∏–π üî¥")

    lines: List[str] = []
    lines.append("# üìä –û—Ç—á—ë—Ç —Å–±–æ—Ä–∫–∏ –¥–æ–º–µ–Ω–æ–≤ KVAS")
    lines.append("")
    lines.append(f"–°–±–æ—Ä–∫–∞: {build_time}")
    lines.append(f"–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π: {repo}")
    lines.append(f"–í—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª: {output}")
    lines.append(f"–õ–∏–º–∏—Ç —Å—Ç—Ä–æ–∫: {max_lines}")
    lines.append("")

    if critical:
        lines.append("üî• –ö—Ä–∏—Ç–∏—á–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã")
        lines.extend(critical)
        lines.append("")

    lines.append("üö¶ –°—Ç–∞—Ç—É—Å —Å–±–æ—Ä–∫–∏")
    lines.append("")
    lines.append("‚úÖ –°–±–æ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞" if classify_severity(state) != "–û–®–ò–ë–ö–ê" else "üö® –°–±–æ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —Å –æ—à–∏–±–∫–∞–º–∏")
    lines.append(warn_line)
    lines.append(f"üßæ –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö —Å—Ç—Ä–æ–∫ –≤ –∏—Ç–æ–≥–æ–≤–æ–º –≤—ã–≤–æ–¥–µ: {bad}")
    lines.append(f"‚úÇÔ∏è –û–±—Ä–µ–∑–∫–∞ –ø–æ –ª–∏–º–∏—Ç—É: {'–ù–ï–¢' if trunc == 0 else '–î–ê'}")
    lines.append("")

    lines.append("üìå –°–≤–æ–¥–∫–∞")
    lines.append("")
    lines.append("itdog")
    lines.append("")
    lines.append(f"–≤—Å–µ–≥–æ: {itdog_total}")
    lines.append(f"–∏–∑–º–µ–Ω–µ–Ω–∏–µ –∫ –ø—Ä–æ—à–ª–æ–º—É –∑–∞–ø—É—Å–∫—É: +{len(it_added)} / -{len(it_removed)}")
    lines.append("")
    lines.append("v2fly (—Ç–æ–ª—å–∫–æ extras ‚Äî –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ itdog)")
    lines.append("")
    lines.append(f"–≤—Å–µ–≥–æ extras: {v2_total}")
    lines.append(f"–∏–∑–º–µ–Ω–µ–Ω–∏–µ –∫ –ø—Ä–æ—à–ª–æ–º—É –∑–∞–ø—É—Å–∫—É: +{len(v2_added)} / -{len(v2_removed)}")
    lines.append(f"–∫–∞—Ç–µ–≥–æ—Ä–∏–∏: {len(cats)} (üü¢ ok={v2_ok} / üî¥ fail={v2_fail} / üü° –ø—É—Å—Ç–æ={len(empty_cats)})")
    lines.append("")
    lines.append("–∏—Ç–æ–≥–æ–≤—ã–π —Å–ø–∏—Å–æ–∫")
    lines.append("")
    lines.append(f"–≤—Å–µ–≥–æ: {final_total}")
    lines.append(f"–∏–∑–º–µ–Ω–µ–Ω–∏–µ –∫ –ø—Ä–æ—à–ª–æ–º—É –∑–∞–ø—É—Å–∫—É: +{len(f_added)} / -{len(f_removed)}")
    lines.append(f"–æ–±—Ä–µ–∑–∞–Ω–æ —Å—Ç—Ä–æ–∫: {trunc}")
    lines.append("")

    lines.append("üìà –õ–∏–º–∏—Ç")
    lines.append("")
    lines.append(f"–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: {final_total} / {max_lines} ({p}% –∑–∞–Ω—è—Ç–æ) {limit_badge(p)}")
    lines.append(f"–±–ª–∏–∑–∫–æ –∫ –ª–∏–º–∏—Ç—É: {near} (–ø–æ—Ä–æ–≥: {threshold}) {near_mark}")
    lines.append("")
    lines.append("–ü—Ä–∞–≤–∏–ª–æ –ø–æ–¥—Å–≤–µ—Ç–∫–∏:")
    lines.append("üü¢ –¥–æ 85% ‚Äî –Ω–æ—Ä–º–∞–ª—å–Ω–æ | üü° 85‚Äì96% ‚Äî –≤–Ω–∏–º–∞–Ω–∏–µ | üî¥ ‚â• 96% ‚Äî –∫—Ä–∏—Ç–∏—á–Ω–æ")
    lines.append("")

    def block_changes(title: str, added: List[str], removed: List[str]) -> None:
        lines.append(title)
        lines.append("‚ûï –î–æ–±–∞–≤–ª–µ–Ω–æ")
        if added:
            lines.extend(added[:20])
        else:
            lines.append("‚Äî")
        lines.append("")
        lines.append("‚ûñ –£–¥–∞–ª–µ–Ω–æ")
        if removed:
            lines.extend(removed[:20])
        else:
            lines.append("‚Äî")
        lines.append("")

    block_changes("üîÑ –ò–∑–º–µ–Ω–µ–Ω–∏—è itdog (—Ç–æ–ø 20)", it_added, it_removed)
    block_changes("üîÑ –ò–∑–º–µ–Ω–µ–Ω–∏—è v2fly extras (—Ç–æ–ø 20)", v2_added, v2_removed)
    block_changes("üîÑ –ò–∑–º–µ–Ω–µ–Ω–∏—è –∏—Ç–æ–≥–æ–≤–æ–≥–æ —Å–ø–∏—Å–∫–∞ (—Ç–æ–ø 20)", f_added, f_removed)

    lines.append("üìÇ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ v2fly –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º")
    lines.append("")
    lines.append("–ö–∞—Ç–µ–≥–æ—Ä–∏—è | –í–∞–ª–∏–¥–Ω—ã—Ö –¥–æ–º–µ–Ω–æ–≤ | –î–æ–±–∞–≤–ª–µ–Ω–æ –≤ extras | –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã—Ö —Å—Ç—Ä–æ–∫ | –ü—Ä–æ–ø—É—â–µ–Ω–æ –¥–∏—Ä–µ–∫—Ç–∏–≤ | –°—Ç–∞—Ç—É—Å")
    lines.append("---|---:|---:|---:|---:|---")
    lines.extend(table_rows)
    lines.append("")
    lines.append("–õ–µ–≥–µ–Ω–¥–∞ —Å—Ç–∞—Ç—É—Å–æ–≤: üü¢ –û–ö | üü° –ü–£–°–¢–û (0 –≤–∞–ª–∏–¥–Ω—ã—Ö –¥–æ–º–µ–Ω–æ–≤) | üî¥ –û–®–ò–ë–ö–ê (—Å–∫–∞—á–∏–≤–∞–Ω–∏–µ/–ø–∞—Ä—Å–∏–Ω–≥)")
    lines.append("")
    lines.append("–ü—Ä–∏–º–µ—á–∞–Ω–∏—è")
    lines.append("- –í–∞–ª–∏–¥–Ω—ã—Ö –¥–æ–º–µ–Ω–æ–≤ ‚Äî –∏–∑–≤–ª–µ—á—ë–Ω–Ω—ã–µ –∏–∑ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞ (full:/domain:/–≥–æ–ª—ã–µ –¥–æ–º–µ–Ω—ã)")
    lines.append("- –î–æ–±–∞–≤–ª–µ–Ω–æ –≤ extras ‚Äî —Ä–µ–∞–ª—å–Ω–æ –ø–æ–ø–∞–ª–∏ –≤ —Ö–≤–æ—Å—Ç (–Ω–µ –ø–µ—Ä–µ—Å–µ–∫–∞—é—Ç—Å—è —Å itdog)")
    lines.append("- –ü—Ä–æ–ø—É—â–µ–Ω–æ –¥–∏—Ä–µ–∫—Ç–∏–≤ ‚Äî include:/regexp:/keyword:/etc (–Ω–µ —Ä–∞–∑–≤–æ—Ä–∞—á–∏–≤–∞—é—Ç—Å—è)")
    lines.append("")

    lines.append("‚ö†Ô∏è –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è")
    lines.append("")
    if failed_cats:
        lines.append("üî¥ –û—à–∏–±–∫–∏ (—Ç—Ä–µ–±—É—é—Ç –≤–Ω–∏–º–∞–Ω–∏—è)")
        lines.append("–ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –Ω–µ —Å–∫–∞—á–∞–ª–∏—Å—å/–Ω–µ —Ä–∞—Å–ø–∞—Ä—Å–∏–ª–∏—Å—å: " + ", ".join(failed_cats))
        lines.append("")
    if empty_cats:
        lines.append("üü° –ê–Ω–æ–º–∞–ª–∏–∏ (–Ω–µ –∫—Ä–∏—Ç–∏—á–Ω–æ, –Ω–æ –ø–æ–ª–µ–∑–Ω–æ –∑–Ω–∞—Ç—å)")
        lines.append("–ü—É—Å—Ç—ã–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ (0 –¥–æ–º–µ–Ω–æ–≤): " + ", ".join(empty_cats))
        lines.append("")
    if not failed_cats and not empty_cats and not warns and trunc == 0 and bad == 0:
        lines.append("‚úÖ –ó–∞–º–µ—á–∞–Ω–∏–π –Ω–µ—Ç")
        lines.append("")

    lines.append("‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞")
    lines.append("")
    lines.append(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ –≤ –≤—ã–≤–æ–¥–µ: {bad}")
    lines.append(f"–û–±—Ä–µ–∑–∫–∞ –ø–æ –ª–∏–º–∏—Ç—É: {'–ù–ï–¢' if trunc == 0 else '–î–ê'}")
    lines.append("")

    lines.append("üîê –•–µ—à–∏")
    lines.append("")
    lines.append(f"sha256(final): {sha}")
    lines.append("")

    lines.append("üß™ –î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Å–±–æ—Ä–∫–∏")
    lines.append("")
    lines.append(f"–∏—Å—Ç–æ—á–Ω–∏–∫ itdog: {itdog_total} –¥–æ–º–µ–Ω–∞ (—É–Ω–∏–∫.)")
    lines.append(f"v2fly extras: {v2_total} –¥–æ–º–µ–Ω–æ–≤ (–ø–æ—Å–ª–µ –≤—ã—á–∏—Ç–∞–Ω–∏—è –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–π)")
    lines.append("–ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏—è itdog ‚à© v2fly: (—Å–∫—Ä—ã—Ç–æ / –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ø—Ä–∏ –∂–µ–ª–∞–Ω–∏–∏)")
    lines.append("")
    lines.append(f"–∏—Ç–æ–≥ –¥–æ –ª–∏–º–∏—Ç–∞: {final_total} —Å—Ç—Ä–æ–∫")
    lines.append(f"–∑–∞–ø–∞—Å –¥–æ –ª–∏–º–∏—Ç–∞: {reserve} —Å—Ç—Ä–æ–∫")
    lines.append(f"—Ä–∏—Å–∫ –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∏—è –ª–∏–º–∏—Ç–∞: {risk}")
    lines.append("")
    lines.append(f"–∑–¥–æ—Ä–æ–≤—å–µ v2fly: fail={max(len(failed_cats), v2_fail)} üî¥ / empty={len(empty_cats)} üü°")
    if failed_cats or empty_cats:
        recs = []
        if failed_cats:
            recs.append("–ø—Ä–æ–≤–µ—Ä–∏—Ç—å " + ", ".join([x.split(" ",1)[0] for x in failed_cats]))
        if empty_cats:
            recs.append("–ø—Ä–æ–≤–µ—Ä–∏—Ç—å " + ", ".join(empty_cats))
        lines.append("—Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è: " + ", ".join(recs))
    return "\n".join(lines).rstrip() + "\n"


def tg_problems_lines(state: Dict) -> List[str]:
    lines: List[str] = []
    failed = state.get("failed_categories") or []
    empty = state.get("empty_categories") or []
    warns = state.get("warnings") or []

    # failed categories: already include "(HTTP ...)" when possible
    for f in failed:
        # "tiktok (HTTP 404)" -> "üî¥ tiktok ‚Äî 404"
        name = str(f)
        m = None
        if "HTTP" in name:
            m = name.split("HTTP", 1)[1].strip().strip("()")
            code = m.split()[0]
            cat = name.split("(", 1)[0].strip()
            lines.append(f"üî¥ {cat} ‚Äî {code}")
        else:
            cat = name.split("(", 1)[0].strip()
            lines.append(f"üî¥ {cat} ‚Äî –æ—à–∏–±–∫–∞")

    for e in empty:
        lines.append(f"üü° {e} ‚Äî –ø—É—Å—Ç–æ")

    max_lines = int(state.get("max_lines", 3000))
    threshold = int(state.get("near_limit_threshold", 2900))
    total = int(state.get("final_total", 0))
    p = pct(total, max_lines)
    if total >= threshold or p >= 96.0:
        lines.append("üü† –ü–æ—á—Ç–∏ –ª–∏–º–∏—Ç")

    trunc = int(state.get("truncated", 0))
    if trunc > 0:
        lines.append(f"üî¥ –æ–±—Ä–µ–∑–∫–∞ ‚Äî {trunc}")

    bad = int(state.get("bad_output_lines", 0))
    if bad > 0:
        lines.append(f"üî¥ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ ‚Äî {bad}")

    # If we have generic warnings that are not categories, keep compact
    # (Do not spam; main problems above are enough.)
    return lines


def format_tg(state: Dict, stats: List[Dict], prev_rec: Optional[Dict]) -> Tuple[str, str]:
    """
    Returns (tg_message, tg_alert).
    """
    sev = classify_severity(state)
    date_s, time_s = fmt_tg_date_time(str(state.get("build_time_utc", "")))

    max_lines = int(state.get("max_lines", 3000))
    total = int(state.get("final_total", 0))
    p = pct(total, max_lines)
    rest = max_lines - total

    sha = short_hash(str(state.get("sha256_final", "")))

    avg7, delta, deviation, eval_line = trend_block(stats, prev_rec, total)

    problems = tg_problems_lines(state)

    # alert text (only when not OK)
    tg_alert = ""
    if sev != "–û–ö" and problems:
        tg_alert = "\n".join(problems) + "\n"

    if sev == "–û–®–ò–ë–ö–ê":
        msg_lines = [
            "üö® –°–±–æ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —Å –æ—à–∏–±–∫–∞–º–∏",
            "üî¥ –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π —Å—Ç–∞—Ç—É—Å",
            "",
            f"üóì {date_s}",
            f"üïí {time_s}",
            "",
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ",
            "üì¶ –†–ï–ó–£–õ–¨–¢–ê–¢",
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ",
            f"üìä {total} / {max_lines} ({p}%)",
            f"üßÆ –û—Å—Ç–∞—Ç–æ–∫: {rest} —Å—Ç—Ä–æ–∫",
            "",
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ",
            "üìà –¢–†–ï–ù–î",
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ",
            f"–°—Ä–µ–¥–Ω–µ–µ (7): {avg7}",
            f"Œî –∫ –ø—Ä–æ—à–ª–æ–π: {delta:+d}",
            f"–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: {deviation:+d}",
            eval_line,
            "",
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ",
            "‚ö† –ü–†–û–ë–õ–ï–ú–´",
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ",
        ]
        msg_lines += (problems if problems else ["‚Äî"])
        msg_lines += ["", f"üîê sha256: {sha}"]
        return "\n".join(msg_lines).rstrip() + "\n", tg_alert

    if sev == "–ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–ï":
        msg_lines = [
            "‚ö†Ô∏è –°–±–æ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —Å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è–º–∏",
            "üü° –¢—Ä–µ–±—É–µ—Ç –≤–Ω–∏–º–∞–Ω–∏—è",
            "",
            f"üóì {date_s}",
            f"üïí {time_s}",
            "",
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ",
            "üì¶ –†–ï–ó–£–õ–¨–¢–ê–¢",
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ",
            f"üìä {total} / {max_lines} ({p}%)",
            f"üßÆ –û—Å—Ç–∞—Ç–æ–∫: {rest} —Å—Ç—Ä–æ–∫",
            "",
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ",
            "üìà –¢–†–ï–ù–î",
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ",
            f"–°—Ä–µ–¥–Ω–µ–µ (7): {avg7}",
            f"Œî –∫ –ø—Ä–æ—à–ª–æ–π: {delta:+d}",
            f"–û—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: {deviation:+d}",
            eval_line,
            "",
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ",
            "‚ö† –ü–†–û–ë–õ–ï–ú–´",
            "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ",
        ]
        msg_lines += (problems if problems else ["‚Äî"])
        msg_lines += ["", f"üîê sha256: {sha}"]
        return "\n".join(msg_lines).rstrip() + "\n", tg_alert

    # OK (short template)
    msg_lines = [
        "üöÄ –°–±–æ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞",
        "üü¢ –°–∏—Å—Ç–µ–º–∞ —Å—Ç–∞–±–∏–ª—å–Ω–∞",
        "",
        f"üóì {date_s}",
        f"üïí {time_s}",
        "",
        f"üìä {total} / {max_lines} ({p}%)",
        "",
        "üìà –¢–†–ï–ù–î",
        f"–°—Ä–µ–¥–Ω–µ–µ (7): {avg7}",
        f"Œî –∫ –ø—Ä–æ—à–ª–æ–π: {delta:+d}",
        eval_line,
        "",
        "‚úÖ –ó–∞–º–µ—á–∞–Ω–∏–π –Ω–µ—Ç" if not problems else "‚ö†Ô∏è –ï—Å—Ç—å –∑–∞–º–µ—á–∞–Ω–∏—è",
        "",
        f"üîê sha256: {sha}",
    ]
    return "\n".join(msg_lines).rstrip() + "\n", tg_alert


def main() -> int:
    DIST.mkdir(parents=True, exist_ok=True)

    state = load_json(STATE_JSON, {})
    if not isinstance(state, dict) or not state:
        # Fallback: create minimal artifacts, do not crash workflow
        now = datetime.now(timezone.utc).replace(microsecond=0).isoformat().replace("+00:00","Z")
        state = {
            "build_time_utc": now,
            "repo": "unknown/unknown",
            "output": "dist/inside-kvas.lst",
            "max_lines": 3000,
            "near_limit_threshold": 2900,
            "sha256_final": "",
            "itdog_domains": [],
            "v2fly_extras": [],
            "final_domains": [],
            "itdog_total": 0,
            "v2fly_total": 0,
            "final_total": 0,
            "truncated": 0,
            "bad_output_lines": 0,
            "v2fly_ok": 0,
            "v2fly_fail": 0,
            "v2fly_categories": [],
            "v2fly_per_category": {},
            "warnings": ["state.json –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç/–ø–æ–≤—Ä–µ–∂–¥—ë–Ω"],
            "failed_categories": [],
            "empty_categories": [],
            "prev": {"itdog_domains": [], "v2fly_extras": [], "final_domains": []},
        }
        dump_json(STATE_JSON, state)

    stats, prev_rec = append_stats(state)

    # report.md
    REPORT_MD.write_text(format_report_md(state, stats, prev_rec), encoding="utf-8")

    # telegram
    tg_msg, tg_alert = format_tg(state, stats, prev_rec)
    TG_MESSAGE.write_text(tg_msg, encoding="utf-8")
    if tg_alert.strip():
        TG_ALERT.write_text(tg_alert, encoding="utf-8")
    else:
        TG_ALERT.unlink(missing_ok=True)

    return 0


if __name__ == "__main__":
    raise SystemExit(main())
