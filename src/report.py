#!/usr/bin/env python3
# -*- coding: utf-8 -*-

from __future__ import annotations

import json
import os
from datetime import datetime, timedelta, timezone
from pathlib import Path
from typing import Dict, List, Optional, Tuple


ROOT = Path(__file__).resolve().parents[1]
DIST_DIR = ROOT / "dist"

STATE_JSON = DIST_DIR / "state.json"
REPORT_OUT = DIST_DIR / "report.md"
TG_MESSAGE_OUT = DIST_DIR / "tg_message.txt"
TG_ALERT_OUT = DIST_DIR / "tg_alert.txt"
STATS_JSON = DIST_DIR / "stats.json"


# ------------------------- helpers -------------------------

def load_json(path: Path, default):
    if not path.exists():
        return default
    try:
        return json.loads(path.read_text(encoding="utf-8"))
    except Exception:
        return default


def short_hash(h: str) -> str:
    h = (h or "").strip()
    if len(h) < 10:
        return h
    return f"{h[:4]}â€¦{h[-4:]}"


def now_msk_dt() -> datetime:
    return datetime.now(timezone.utc).astimezone(timezone(timedelta(hours=3)))


def format_date_msk(d: datetime) -> str:
    return d.strftime("%d.%m.%Y")


def format_time_msk(d: datetime) -> str:
    return d.strftime("%H:%M:%S ĞœĞ¡Ğš")


def format_build_time_msk_from_state(build_time_utc_raw: str) -> str:
    """
    state.json Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ build_time_utc ĞºĞ°Ğº 'YYYY-MM-DD HH:MM:SS UTC'
    Ğ¸Ğ»Ğ¸ 'YYYY-MM-DD HH:MM:SS'
    """
    s = (build_time_utc_raw or "").replace("UTC", "").strip()
    try:
        dt_utc = datetime.strptime(s, "%Y-%m-%d %H:%M:%S").replace(tzinfo=timezone.utc)
        dt_msk = dt_utc.astimezone(timezone(timedelta(hours=3)))
    except Exception:
        return s or "â€”"

    months = ["ÑĞ½Ğ²", "Ñ„ĞµĞ²", "Ğ¼Ğ°Ñ€", "Ğ°Ğ¿Ñ€", "Ğ¼Ğ°Ñ", "Ğ¸ÑĞ½", "Ğ¸ÑĞ»", "Ğ°Ğ²Ğ³", "ÑĞµĞ½", "Ğ¾ĞºÑ‚", "Ğ½Ğ¾Ñ", "Ğ´ĞµĞº"]
    m = months[dt_msk.month - 1]
    return f"{dt_msk.day:02d} {m} {dt_msk.year}, {dt_msk:%H:%M} ĞœĞ¡Ğš"


def diff_counts(prev_list: List[str], curr_list: List[str]) -> Tuple[int, int]:
    prev = set(prev_list or [])
    curr = set(curr_list or [])
    added = len(curr - prev)
    removed = len(prev - curr)
    return added, removed


def format_change(added: int, removed: int) -> str:
    return f"+{added} / âˆ’{removed}"


def usage_badge(pct: float) -> str:
    # ğŸŸ¢ <85, ğŸŸ¡ 85â€“96, ğŸ”´ â‰¥96
    if pct >= 96.0:
        return "ğŸ”´"
    if pct >= 85.0:
        return "ğŸŸ¡"
    return "ğŸŸ¢"


def near_limit_flag(total: int, threshold: int) -> bool:
    return total >= threshold


def status_text_table(status: str) -> str:
    s = (status or "").strip()
    if s.startswith("OK"):
        return "ğŸŸ¢ ĞĞš"
    if s.startswith("EMPTY"):
        return "ğŸŸ¡ ĞŸĞ£Ğ¡Ğ¢Ğ"
    if s.startswith("FAIL"):
        return "ğŸ”´ ĞĞ¨Ğ˜Ğ‘ĞšĞ"
    # fallback
    return s or "â€”"


def build_run_url() -> Optional[str]:
    server = os.getenv("GITHUB_SERVER_URL", "").strip()
    repo = os.getenv("GITHUB_REPOSITORY", "").strip()
    run_id = os.getenv("GITHUB_RUN_ID", "").strip()
    if server and repo and run_id:
        return f"{server}/{repo}/actions/runs/{run_id}"
    return None


def append_stats(total: int, itdog: int, v2fly: int, warnings: List[str]) -> Optional[int]:
    """
    Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ delta_total (Ñ‚ĞµĞºÑƒÑ‰Ğ¸Ğ¹ total - Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰Ğ¸Ğ¹ total) Ğ¸Ğ»Ğ¸ None, ĞµÑĞ»Ğ¸ Ğ¿Ñ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰ĞµĞ¹ Ğ·Ğ°Ğ¿Ğ¸ÑĞ¸ Ğ½ĞµÑ‚.
    """
    data = load_json(STATS_JSON, [])
    if not isinstance(data, list):
        data = []

    prev = data[-1] if data else None
    prev_total = prev.get("total") if isinstance(prev, dict) else None

    rec = {
        "ts_utc": datetime.now(timezone.utc).replace(microsecond=0).isoformat(),
        "total": total,
        "itdog": itdog,
        "v2fly": v2fly,
        "warnings": warnings,
    }
    data.append(rec)
    data = data[-400:]
    STATS_JSON.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")

    if isinstance(prev_total, int):
        return total - prev_total
    return None


def last_totals_from_stats(n: int = 7) -> List[int]:
    data = load_json(STATS_JSON, [])
    if not isinstance(data, list) or not data:
        return []
    totals: List[int] = []
    for row in data[-n:]:
        if isinstance(row, dict) and isinstance(row.get("total"), int):
            totals.append(int(row["total"]))
    return totals


def avg(nums: List[int]) -> Optional[float]:
    if not nums:
        return None
    return sum(nums) / len(nums)


def ascii_trend_block(values: List[int]) -> str:
    """
    ĞĞ´Ğ½Ğ¾ÑÑ‚Ñ€Ğ¾Ñ‡Ğ½Ñ‹Ğ¹ Ğ¼Ğ¸Ğ½Ğ¸-Ğ³Ñ€Ğ°Ñ„Ğ¸Ğº Ğ½Ğ° 7 Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğ¹.
    """
    if len(values) < 2:
        return "â€”"

    vmin = min(values)
    vmax = max(values)
    span = max(1, vmax - vmin)

    bars = "â–â–‚â–ƒâ–„â–…â–†â–‡â–ˆ"
    line = []
    for v in values:
        idx = int(round((v - vmin) / span * (len(bars) - 1)))
        idx = max(0, min(len(bars) - 1, idx))
        line.append(bars[idx])

    return f"{vmin} {''.join(line)} {vmax}"


def trend_label(curr_delta: Optional[int], avg_delta: Optional[float]) -> Tuple[str, str]:
    """
    Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ (ÑÑ‚Ñ€ĞµĞ»ĞºĞ°/Ğ»ĞµĞ¹Ğ±Ğ», Ğ¾Ñ†ĞµĞ½ĞºĞ°)
    """
    if curr_delta is None:
        return "â¡", "Ğ½ĞµĞ´Ğ¾ÑÑ‚Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ¾ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…"

    if curr_delta > 0:
        arrow = "ğŸ“ˆ"
    elif curr_delta < 0:
        arrow = "ğŸ“‰"
    else:
        arrow = "â¡"

    if avg_delta is None or avg_delta == 0:
        return arrow, "â€”"

    ratio = abs(curr_delta) / abs(avg_delta) if avg_delta != 0 else None
    if ratio is None:
        return arrow, "â€”"

    if ratio >= 2.0 and abs(curr_delta) >= 10:
        return arrow, "âš  Ğ²Ñ‹ÑˆĞµ ÑÑ€ĞµĞ´Ğ½ĞµĞ³Ğ¾ Ã—2"
    return arrow, "Ğ½Ğ¾Ñ€Ğ¼Ğ°"


def build_completion_line(has_errors: bool, has_warnings: bool) -> str:
    if has_errors:
        return "ğŸš¨ Ğ¡Ğ±Ğ¾Ñ€ĞºĞ° Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ° Ñ Ğ¾ÑˆĞ¸Ğ±ĞºĞ°Ğ¼Ğ¸"
    if has_warnings:
        return "âš ï¸ Ğ¡Ğ±Ğ¾Ñ€ĞºĞ° Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ° Ñ Ğ¿Ñ€ĞµĞ´ÑƒĞ¿Ñ€ĞµĞ¶Ğ´ĞµĞ½Ğ¸ÑĞ¼Ğ¸"
    return "ğŸš€ Ğ¡Ğ±Ğ¾Ñ€ĞºĞ° Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ°"


def build_system_line(system_level: str) -> str:
    if system_level == "critical":
        return "ğŸ”´ ĞšÑ€Ğ¸Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ ÑÑ‚Ğ°Ñ‚ÑƒÑ"
    if system_level == "attention":
        return "ğŸŸ¡ Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ"
    return "ğŸŸ¢ Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ°"


def main() -> int:
    state = load_json(STATE_JSON, {})
    if not isinstance(state, dict):
        raise SystemExit("Bad dist/state.json")

    prev = state.get("prev", {}) if isinstance(state.get("prev"), dict) else {}

    repo = str(state.get("repo", "unknown/unknown"))
    output = str(state.get("output", "dist/inside-kvas.lst"))
    max_lines = int(state.get("max_lines", 3000))
    threshold = int(state.get("near_limit_threshold", 2900))

    itdog_domains = state.get("itdog_domains", []) or []
    v2fly_extras = state.get("v2fly_extras", []) or []
    final_domains = state.get("final_domains", []) or []
    if not isinstance(itdog_domains, list): itdog_domains = []
    if not isinstance(v2fly_extras, list): v2fly_extras = []
    if not isinstance(final_domains, list): final_domains = []

    itdog_total = len(set(itdog_domains))
    v2fly_total = len(set(v2fly_extras))
    final_total = len(set(final_domains))

    it_add, it_rem = diff_counts(prev.get("itdog_domains", []) or [], itdog_domains)
    v2_add, v2_rem = diff_counts(prev.get("v2fly_extras", []) or [], v2fly_extras)
    f_add, f_rem = diff_counts(prev.get("final_domains", []) or [], final_domains)

    it_change = format_change(it_add, it_rem)
    v2_change = format_change(v2_add, v2_rem)
    f_change = format_change(f_add, f_rem)

    v2fly_ok = int(state.get("v2fly_ok", 0))
    v2fly_fail = int(state.get("v2fly_fail", 0))
    truncated_count = int(state.get("truncated", 0))
    bad_output_lines = int(state.get("bad_output_lines", 0))

    warnings = state.get("warnings", []) or []
    failed_categories = state.get("failed_categories", []) or []
    empty_categories = state.get("empty_categories", []) or []
    if not isinstance(warnings, list): warnings = []
    if not isinstance(failed_categories, list): failed_categories = []
    if not isinstance(empty_categories, list): empty_categories = []

    usage_pct = round((final_total / max_lines) * 100, 1) if max_lines else 0.0
    badge = usage_badge(usage_pct)
    near_limit = near_limit_flag(final_total, threshold)

    has_errors = (v2fly_fail > 0) or (bad_output_lines > 0)
    has_warnings = bool(warnings) or bool(empty_categories) or near_limit or (truncated_count > 0)

    if has_errors or usage_pct >= 96.0:
        system_level = "critical"
    elif has_warnings or usage_pct >= 85.0:
        system_level = "attention"
    else:
        system_level = "stable"

    completion_line = build_completion_line(has_errors, has_warnings)
    system_line = build_system_line(system_level)

    build_time_utc = str(state.get("build_time_utc", "")).replace(" UTC", "")
    build_time_msk = format_build_time_msk_from_state(build_time_utc)

    sha = short_hash(str(state.get("sha256_final", "")))

    # trend
    delta_total = append_stats(final_total, itdog_total, v2fly_total, warnings)
    totals7_after = last_totals_from_stats(7)
    avg7 = avg(totals7_after)
    avg7_int = int(round(avg7)) if avg7 is not None else None
    deviation = (final_total - avg7_int) if avg7_int is not None else None

    deltas: List[int] = []
    if len(totals7_after) >= 2:
        for i in range(1, len(totals7_after)):
            deltas.append(totals7_after[i] - totals7_after[i - 1])
    avg_delta = avg(deltas) if deltas else None

    arrow, growth_eval = trend_label(delta_total, avg_delta)
    trend_ascii = ascii_trend_block(totals7_after) if totals7_after else "â€”"

    # intersection
    intersection = len(set(itdog_domains) & set(v2fly_extras))

    # v2fly per-category table (translated status)
    cats = state.get("v2fly_categories", []) or []
    per_cat = state.get("v2fly_per_category", {}) or {}
    if not isinstance(cats, list): cats = []
    if not isinstance(per_cat, dict): per_cat = {}
    cats_total = len(cats)

    table_rows: List[str] = []
    for cat in cats:
        d = per_cat.get(cat, {}) if isinstance(per_cat.get(cat, {}), dict) else {}
        table_rows.append(
            f"| {cat} | {int(d.get('valid_domains', 0))} | {int(d.get('extras_added', 0))} | "
            f"{int(d.get('invalid_lines', 0))} | {int(d.get('skipped_directives', 0))} | {status_text_table(str(d.get('status', '')))} |"
        )
    table_block = "\n".join(table_rows) if table_rows else "| â€” | 0 | 0 | 0 | 0 | â€” |"

    failed_inline = "none" if not failed_categories else ", ".join(failed_categories)
    empty_inline = "none" if not empty_categories else ", ".join(empty_categories)

    # report.md
    deviation_txt = "â€”" if deviation is None else (f"+{deviation}" if deviation >= 0 else str(deviation))
    delta_txt = "â€”" if delta_total is None else f"{delta_total:+d}"
    avg_delta_txt = "â€”" if avg_delta is None else f"{avg_delta:+.1f}"

    report = f"""# ğŸ“Š ĞÑ‚Ñ‡Ñ‘Ñ‚ ÑĞ±Ğ¾Ñ€ĞºĞ¸ Ğ´Ğ¾Ğ¼ĞµĞ½Ğ¾Ğ² KVAS

{completion_line}
{system_line}

**Ğ¡Ğ±Ğ¾Ñ€ĞºĞ°:** {build_time_msk}
**Ğ ĞµĞ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ¹:** {repo}
**Ğ¤Ğ°Ğ¹Ğ»:** {output}
**Ğ›Ğ¸Ğ¼Ğ¸Ñ‚:** {max_lines} ÑÑ‚Ñ€Ğ¾Ğº

---

## ğŸ“¦ Ğ ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚

| ĞŸĞ¾ĞºĞ°Ğ·Ğ°Ñ‚ĞµĞ»ÑŒ | Ğ—Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ |
|---|---:|
| Ğ˜Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ñ‹Ñ… ÑÑ‚Ñ€Ğ¾Ğº | **{final_total}** |
| Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ | **{usage_pct}%** {badge} |
| Ğ—Ğ°Ğ¿Ğ°Ñ Ğ´Ğ¾ Ğ»Ğ¸Ğ¼Ğ¸Ñ‚Ğ° | **{max_lines - final_total}** ÑÑ‚Ñ€Ğ¾Ğº |
| Ğ‘Ğ»Ğ¸Ğ·ĞºĞ¾ Ğº Ğ»Ğ¸Ğ¼Ğ¸Ñ‚Ñƒ (â‰¥ {threshold}) | **{"Ğ”Ğ" if near_limit else "ĞĞ•Ğ¢"}** |
| ĞĞ±Ñ€ĞµĞ·ĞºĞ° Ğ¿Ğ¾ Ğ»Ğ¸Ğ¼Ğ¸Ñ‚Ñƒ | **{"Ğ”Ğ" if truncated_count > 0 else "ĞĞ•Ğ¢"}** |
| ĞĞµĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ñ‹Ğµ ÑÑ‚Ñ€Ğ¾ĞºĞ¸ Ğ² Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğµ | **{bad_output_lines}** |

---

## ğŸ“ˆ Ğ¢Ñ€ĞµĞ½Ğ´ (Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğµ 7 ÑĞ±Ğ¾Ñ€Ğ¾Ğº)

- Ğ¡Ñ€ĞµĞ´Ğ½ĞµĞµ Ğ·Ğ° 7: **{avg7_int if avg7_int is not None else "â€”"}**
- Ğ¢ĞµĞºÑƒÑ‰Ğ¸Ğ¹ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚: **{final_total}**
- ĞÑ‚ĞºĞ»Ğ¾Ğ½ĞµĞ½Ğ¸Ğµ Ğ¾Ñ‚ ÑÑ€ĞµĞ´Ğ½ĞµĞ³Ğ¾: **{deviation_txt}**
- Ğ˜Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ Ğº Ğ¿Ñ€Ğ¾ÑˆĞ»Ğ¾Ğ¹ ÑĞ±Ğ¾Ñ€ĞºĞµ: **{delta_txt}**
- Ğ¡Ñ€ĞµĞ´Ğ½Ğ¸Ğ¹ Ğ¿Ñ€Ğ¸Ñ€Ğ¾ÑÑ‚ Ğ·Ğ° 7: **{avg_delta_txt}**
- Ğ”Ğ¸Ğ½Ğ°Ğ¼Ğ¸ĞºĞ°: {arrow} ({growth_eval})

ĞœĞ¸Ğ½Ğ¸-Ğ³Ñ€Ğ°Ñ„Ğ¸Ğº:
```
{trend_ascii}
```

---

## ğŸ”„ Ğ˜Ğ·Ğ¼ĞµĞ½ĞµĞ½Ğ¸Ñ (Ğ¾Ñ‚Ğ½Ğ¾ÑĞ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ¿Ñ€Ğ¾ÑˆĞ»Ğ¾Ğ¹ ÑĞ±Ğ¾Ñ€ĞºĞ¸)

| Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸Ğº | Î” | Ğ’ÑĞµĞ³Ğ¾ |
|---|---:|---:|
| ğŸŸ¦ itdog | {it_change} | {itdog_total} |
| ğŸŸ© v2fly extras | {v2_change} | {v2fly_total} |
| ğŸ§© Ğ¸Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ñ‹Ğ¹ Ñ„Ğ°Ğ¹Ğ» | {f_change} | {final_total} |

---

## ğŸ“‚ Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° v2fly Ğ¿Ğ¾ ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸ÑĞ¼

| category | valid_domains | extras_added | invalid_lines | skipped_directives | status |
|---|---:|---:|---:|---:|---|
{table_block}

ĞŸÑ€Ğ¸Ğ¼ĞµÑ‡Ğ°Ğ½Ğ¸Ñ:
- `valid_domains` = Ğ´Ğ¾Ğ¼ĞµĞ½Ñ‹, Ğ¸Ğ·Ğ²Ğ»ĞµÑ‡Ñ‘Ğ½Ğ½Ñ‹Ğµ Ğ¸Ğ· ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ğ¸ (full:/domain:/Ğ³Ğ¾Ğ»Ñ‹Ğµ Ğ´Ğ¾Ğ¼ĞµĞ½Ñ‹)
- `extras_added` = Ğ´Ğ¾Ğ¼ĞµĞ½Ñ‹, Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾ Ğ¿Ğ¾Ğ¿Ğ°Ğ²ÑˆĞ¸Ğµ Ğ² Ñ…Ğ²Ğ¾ÑÑ‚ (Ğ½Ğµ Ğ¿ĞµÑ€ĞµÑĞµĞºĞ°ÑÑ‚ÑÑ Ñ itdog)
- `skipped_directives` = include:/regexp:/keyword:/etc (Ğ½Ğµ Ñ€Ğ°Ğ·Ğ²Ğ¾Ñ€Ğ°Ñ‡Ğ¸Ğ²Ğ°ÑÑ‚ÑÑ)

---

## âš  ĞŸÑ€ĞµĞ´ÑƒĞ¿Ñ€ĞµĞ¶Ğ´ĞµĞ½Ğ¸Ñ

- ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ğ¸ (ÑĞºĞ°Ñ‡Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğµ/Ğ¿Ğ°Ñ€ÑĞ¸Ğ½Ğ³): {failed_inline}
- ĞŸÑƒÑÑ‚Ñ‹Ğµ ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ğ¸ (0 Ğ´Ğ¾Ğ¼ĞµĞ½Ğ¾Ğ²): {empty_inline}
- ĞŸĞ¾Ñ‡Ñ‚Ğ¸ Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ½ÑƒÑ‚ Ğ»Ğ¸Ğ¼Ğ¸Ñ‚ (â‰¥ {threshold} ÑÑ‚Ñ€Ğ¾Ğº): {"Ğ”Ğ" if near_limit else "ĞĞ•Ğ¢"}
- ĞĞµĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ñ‹Ğµ ÑÑ‚Ñ€Ğ¾ĞºĞ¸ Ğ² Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğµ: {bad_output_lines}
- ĞĞ±Ñ€ĞµĞ·ĞºĞ° Ğ¿Ğ¾ Ğ»Ğ¸Ğ¼Ğ¸Ñ‚Ñƒ: {"Ğ”Ğ" if truncated_count > 0 else "ĞĞ•Ğ¢"}

---

## ğŸ§ª Ğ”Ğ¸Ğ°Ğ³Ğ½Ğ¾ÑÑ‚Ğ¸ĞºĞ°

- itdog ÑƒĞ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ñ…: **{itdog_total}**
- v2fly extras: **{v2fly_total}**
- ĞŸĞµÑ€ĞµÑĞµÑ‡ĞµĞ½Ğ¸Ğµ itdog âˆ© v2fly: **{intersection}**
- Ğ—Ğ°Ğ¿Ğ°Ñ Ğ´Ğ¾ Ğ»Ğ¸Ğ¼Ğ¸Ñ‚Ğ°: **{max_lines - final_total}** ÑÑ‚Ñ€Ğ¾Ğº
- v2fly ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ğ¹: **{cats_total}** (ok={v2fly_ok}, fail={v2fly_fail}, Ğ¿ÑƒÑÑ‚Ğ¾={len(empty_categories)})

---

## ğŸ” Ğ¥ĞµÑˆ

`sha256: {sha}`
"""
    REPORT_OUT.write_text(report, encoding="utf-8")

    # Telegram caption (Ğ±Ğ¾ĞµĞ²Ğ¾Ğ¹ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚)
    msk_now = now_msk_dt()
    tg_date = format_date_msk(msk_now)
    tg_time = format_time_msk(msk_now)
    run_url = build_run_url()

    if usage_pct >= 96.0:
        limit_state = "ğŸ”´ ĞšĞ Ğ˜Ğ¢Ğ˜Ğ§Ğ•Ğ¡ĞšĞĞ• Ğ¿Ñ€Ğ¸Ğ±Ğ»Ğ¸Ğ¶ĞµĞ½Ğ¸Ğµ Ğº Ğ»Ğ¸Ğ¼Ğ¸Ñ‚Ñƒ"
    elif usage_pct >= 85.0:
        limit_state = "ğŸŸ¡ Ğ¢Ñ€ĞµĞ±ÑƒĞµÑ‚ Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ñ (Ğ»Ğ¸Ğ¼Ğ¸Ñ‚)"
    else:
        limit_state = "ğŸŸ¢ Ğ›Ğ¸Ğ¼Ğ¸Ñ‚ Ğ² Ğ½Ğ¾Ñ€Ğ¼Ğµ"

    rest_line = f"ğŸ§® ĞÑÑ‚Ğ°Ñ‚Ğ¾Ğº: {max_lines - final_total} ÑÑ‚Ñ€Ğ¾Ğº" if usage_pct >= 85.0 else None

    avg7_txt = str(avg7_int) if avg7_int is not None else "â€”"
    tg_delta_txt = "â€”" if delta_total is None else f"{delta_total:+d}"
    dev_txt = "â€”" if deviation is None else (f"+{deviation}" if deviation >= 0 else str(deviation))
    trend_eval_line = f"{arrow} {('Ğ Ğ¾ÑÑ‚' if arrow=='ğŸ“ˆ' else ('ĞŸĞ°Ğ´ĞµĞ½Ğ¸Ğµ' if arrow=='ğŸ“‰' else 'Ğ¡Ñ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾'))}"
    if growth_eval.startswith("âš "):
        trend_eval_line += f" ({growth_eval})"

    problems: List[str] = []
    if failed_categories:
        problems.append("ğŸ”´ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸: " + ", ".join(failed_categories[:3]))
    if empty_categories:
        problems.append("ğŸŸ¡ ĞŸÑƒÑÑ‚Ñ‹Ğµ ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ğ¸: " + ", ".join(empty_categories[:6]))
    if near_limit:
        problems.append(f"ğŸŸ  ĞŸĞ¾Ñ‡Ñ‚Ğ¸ Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ½ÑƒÑ‚ Ğ»Ğ¸Ğ¼Ğ¸Ñ‚ (â‰¥ {threshold})")

    tg_lines: List[str] = [
        completion_line,
        system_line,
        "",
        f"ğŸ—“ {tg_date}",
        f"ğŸ•’ {tg_time}",
        "",
        "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”",
        "ğŸ“¦ Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢",
        "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”",
        "ğŸ“„ inside-kvas.lst",
        f"ğŸ“Š {final_total} / {max_lines} ({usage_pct}%)",
        limit_state,
    ]
    if rest_line:
        tg_lines.append(rest_line)

    tg_lines += [
        "",
        "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”",
        "ğŸ”„ Ğ˜Ğ—ĞœĞ•ĞĞ•ĞĞ˜Ğ¯",
        "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”",
        f"ğŸŸ¦ itdog         {it_change}   ({itdog_total})",
        f"ğŸŸ© v2fly extras  {v2_change}   ({v2fly_total})",
        f"ğŸ§© Ğ¸Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ñ‹Ğ¹ Ñ„Ğ°Ğ¹Ğ» {f_change}   ({final_total})",
        "",
        "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”",
        "ğŸ“ˆ Ğ¢Ğ Ğ•ĞĞ”",
        "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”",
        f"Ğ¡Ñ€ĞµĞ´Ğ½ĞµĞµ (7): {avg7_txt}",
        f"Î” Ğº Ğ¿Ñ€Ğ¾ÑˆĞ»Ğ¾Ğ¹: {tg_delta_txt}",
        f"ĞÑ‚ĞºĞ»Ğ¾Ğ½ĞµĞ½Ğ¸Ğµ: {dev_txt}",
        trend_eval_line,
    ]

    if has_errors or has_warnings:
        tg_lines += [
            "",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”",
            "âš  Ğ¢Ğ Ğ•Ğ‘Ğ£Ğ•Ğ¢Ğ¡Ğ¯ Ğ’ĞœĞ•Ğ¨ĞĞ¢Ğ•Ğ›Ğ¬Ğ¡Ğ¢Ğ’Ğ" if (has_errors or usage_pct >= 96.0) else "âš  ĞŸĞ ĞĞ‘Ğ›Ğ•ĞœĞ«",
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”",
        ]
        if problems:
            tg_lines.extend(problems)
        else:
            tg_lines.append("âš  Ğ•ÑÑ‚ÑŒ Ğ¿Ñ€ĞµĞ´ÑƒĞ¿Ñ€ĞµĞ¶Ğ´ĞµĞ½Ğ¸Ñ (Ğ´ĞµÑ‚Ğ°Ğ»Ğ¸ Ğ² Ğ¾Ñ‚Ñ‡Ñ‘Ñ‚Ğµ)")
    else:
        tg_lines += ["", "âœ… Ğ—Ğ°Ğ¼ĞµÑ‡Ğ°Ğ½Ğ¸Ğ¹ Ğ½ĞµÑ‚"]

    tg_lines += ["", f"ğŸ” sha256: {sha}"]

    if run_url:
        tg_lines += ["", "ğŸ” Run:", run_url]

    tg_lines += ["", "ğŸ“ ĞŸĞ¾Ğ»Ğ½Ñ‹Ğ¹ Ğ¾Ñ‚Ñ‡Ñ‘Ñ‚ Ğ²Ğ¾ Ğ²Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¸"]

    TG_MESSAGE_OUT.write_text("\n".join(tg_lines).strip() + "\n", encoding="utf-8")

    # Telegram alert (Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ğ¾) â€” Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ ĞµÑĞ»Ğ¸ Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾ ĞµÑÑ‚ÑŒ Ğ¿Ñ€ĞµĞ´ÑƒĞ¿Ñ€ĞµĞ¶Ğ´ĞµĞ½Ğ¸Ñ/Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸
    if has_errors or has_warnings:
        alert_lines: List[str] = [
            "âš ï¸ KVAS Domains â€” Ğ¿Ñ€ĞµĞ´ÑƒĞ¿Ñ€ĞµĞ¶Ğ´ĞµĞ½Ğ¸Ñ",
            f"ğŸ•’ {tg_date} {tg_time}",
            "",
        ]

        if failed_categories:
            alert_lines.append("ğŸ”´ ĞÑˆĞ¸Ğ±ĞºĞ¸ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ğ¹:")
            for x in failed_categories[:20]:
                alert_lines.append(f"- {x}")
            alert_lines.append("")

        if near_limit:
            alert_lines.append(f"ğŸŸ  ĞŸĞ¾Ñ‡Ñ‚Ğ¸ Ğ´Ğ¾ÑÑ‚Ğ¸Ğ³Ğ½ÑƒÑ‚ Ğ»Ğ¸Ğ¼Ğ¸Ñ‚ (â‰¥ {threshold} ÑÑ‚Ñ€Ğ¾Ğº)")
            alert_lines.append("")

        if empty_categories:
            alert_lines.append("ğŸŸ¡ ĞŸÑƒÑÑ‚Ñ‹Ğµ ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ğ¸:")
            for x in empty_categories[:30]:
                alert_lines.append(f"- {x}")
            alert_lines.append("")

        if warnings:
            alert_lines.append("â„¹ï¸ ĞŸÑ€Ğ¾Ñ‡Ğ¸Ğµ Ğ¿Ñ€ĞµĞ´ÑƒĞ¿Ñ€ĞµĞ¶Ğ´ĞµĞ½Ğ¸Ñ:")
            for w in warnings[:30]:
                alert_lines.append(f"- {w}")

        TG_ALERT_OUT.write_text("\n".join(alert_lines).strip() + "\n", encoding="utf-8")
    else:
        TG_ALERT_OUT.unlink(missing_ok=True)

    return 0


if __name__ == "__main__":
    raise SystemExit(main())
