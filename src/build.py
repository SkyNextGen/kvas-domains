#!/usr/bin/env python3
# -*- coding: utf-8 -*-

from __future__ import annotations

import hashlib
import json
import re
from dataclasses import dataclass
from datetime import datetime, timezone, timedelta
from pathlib import Path
from typing import Dict, Iterable, List, Optional, Tuple
from urllib.error import HTTPError, URLError
from urllib.request import Request, urlopen


ROOT = Path(__file__).resolve().parents[1]
SRC_DIR = ROOT / "src"
DIST_DIR = ROOT / "dist"
HISTORY_DIR = DIST_DIR / "history"

# ------------------------- config -------------------------

# itdog (Ð±Ð°Ð·Ð°)
ITDOG_URL = "https://raw.githubusercontent.com/itdoginfo/allow-domains/main/Russia/inside-kvas.lst"

# v2fly (ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð¸ -> data/<category>)
V2FLY_DATA_BASE = "https://raw.githubusercontent.com/v2fly/domain-list-community/master/data"
V2FLY_CATEGORIES_FILE = SRC_DIR / "v2fly_allow.txt"

# outputs
FINAL_OUT = DIST_DIR / "inside-kvas.lst"
DEBUG_V2FLY = DIST_DIR / "debug_v2fly.txt"
STATE_JSON = DIST_DIR / "state.json"

# limits
MAX_LINES = 3000
NEAR_LIMIT_THRESHOLD = 2900

# history
MAX_HISTORY = 12

DOMAIN_RE = re.compile(
    r"^(?:[a-z0-9](?:[a-z0-9-]{0,61}[a-z0-9])?\.)+[a-z0-9-]{2,63}$",
    re.IGNORECASE,
)

# Ð’ v2fly Ð±ÐµÑ€Ñ‘Ð¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð´Ð¾Ð¼ÐµÐ½Ñ‹ (plain / domain: / full:)
V2FLY_PREFIXES = ("full:", "domain:")

# Ð”Ð¸Ñ€ÐµÐºÑ‚Ð¸Ð²Ñ‹ v2fly, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ð½Ðµ Ñ€Ð°Ð·Ð²Ð¾Ñ€Ð°Ñ‡Ð¸Ð²Ð°ÐµÐ¼ Ð² Ð´Ð¾Ð¼ÐµÐ½Ñ‹
V2FLY_DIRECTIVE_PREFIXES = (
    "include:",
    "regexp:",
    "keyword:",
    "ext:",
    "full-regexp:",
    "domain-regexp:",
    "suffix:",
)


@dataclass
class FetchResult:
    ok: bool
    text: str
    error: Optional[str] = None
    status: Optional[int] = None


# ------------------------- helpers -------------------------

def ensure_dirs() -> None:
    DIST_DIR.mkdir(parents=True, exist_ok=True)
    HISTORY_DIR.mkdir(parents=True, exist_ok=True)


def now_utc_dt() -> datetime:
    return datetime.now(timezone.utc).replace(microsecond=0)


def build_time_utc_str(dt: datetime) -> str:
    return dt.strftime("%Y-%m-%d %H:%M:%S UTC")


def http_get_text(url: str, timeout: int = 30) -> FetchResult:
    req = Request(url, headers={"User-Agent": "kvas-domains-builder/2.0"})
    try:
        with urlopen(req, timeout=timeout) as resp:
            charset = resp.headers.get_content_charset() or "utf-8"
            data = resp.read().decode(charset, errors="replace")
            return FetchResult(ok=True, text=data, status=getattr(resp, "status", None))
    except HTTPError as e:
        return FetchResult(ok=False, text="", error=f"HTTP {e.code}: {e.reason}", status=e.code)
    except URLError as e:
        return FetchResult(ok=False, text="", error=str(e), status=None)
    except Exception as e:
        return FetchResult(ok=False, text="", error=str(e), status=None)


def is_domain(s: str) -> bool:
    return bool(DOMAIN_RE.match(s.strip().lower()))


def normalize_domain(s: str) -> Optional[str]:
    s = s.strip().lower().replace("\r", "")
    if not s:
        return None
    if s.endswith("."):
        s = s[:-1]
    return s if is_domain(s) else None


def parse_itdog(text: str) -> List[str]:
    out: List[str] = []
    for raw in text.splitlines():
        line = raw.strip()
        if not line or line.startswith("#"):
            continue
        dom = normalize_domain(line)
        if dom:
            out.append(dom)
    return out


def parse_v2fly_file_with_stats(text: str) -> Tuple[List[str], int, int]:
    """Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ (Ð´Ð¾Ð¼ÐµÐ½Ñ‹, invalid_lines, skipped_directives)."""
    out: List[str] = []
    invalid_lines = 0
    skipped_directives = 0

    for raw in text.splitlines():
        line = raw.strip()
        if not line or line.startswith("#"):
            continue

        if any(line.startswith(p) for p in V2FLY_PREFIXES):
            _, val = line.split(":", 1)
            dom = normalize_domain(val)
            if dom:
                out.append(dom)
            else:
                invalid_lines += 1
            continue

        if any(line.startswith(p) for p in V2FLY_DIRECTIVE_PREFIXES):
            skipped_directives += 1
            continue

        # ÐÐµÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¸Ð²Ñ‹ Ð²Ñ‹Ð³Ð»ÑÐ´ÑÑ‚ ÐºÐ°Ðº "something:..."
        if ":" in line and not is_domain(line):
            skipped_directives += 1
            continue

        dom = normalize_domain(line)
        if dom:
            out.append(dom)
        else:
            invalid_lines += 1

    return out, invalid_lines, skipped_directives


def read_v2fly_categories(path: Path) -> List[str]:
    if not path.exists():
        return []
    cats: List[str] = []
    for raw in path.read_text(encoding="utf-8").splitlines():
        line = raw.strip()
        if not line or line.startswith("#"):
            continue
        cats.append(line)
    return cats


def load_json(path: Path, default):
    if not path.exists():
        return default
    try:
        return json.loads(path.read_text(encoding="utf-8"))
    except Exception:
        return default


def dump_json(path: Path, obj) -> None:
    path.parent.mkdir(parents=True, exist_ok=True)
    path.write_text(json.dumps(obj, ensure_ascii=False, indent=2), encoding="utf-8")


def sha256_file(path: Path) -> str:
    h = hashlib.sha256()
    with path.open("rb") as f:
        for chunk in iter(lambda: f.read(1024 * 1024), b""):
            h.update(chunk)
    return h.hexdigest()


def rotate_history(history_dir: Path, max_items: int) -> None:
    snaps = sorted(history_dir.glob("snapshot-*.lst"))
    for p in snaps[:-max_items]:
        p.unlink(missing_ok=True)

    diffs = sorted(history_dir.glob("diff-*.txt"))
    for p in diffs[:-max_items]:
        p.unlink(missing_ok=True)


def diff_lists(prev: Iterable[str], curr: Iterable[str]) -> Tuple[List[str], List[str]]:
    prev_set = set(prev)
    curr_set = set(curr)
    added = sorted(curr_set - prev_set)
    removed = sorted(prev_set - curr_set)
    return added, removed


def now_stamp(dt: datetime) -> str:
    return dt.strftime("%Y%m%d-%H%M%S")


# ------------------------- main -------------------------

def main() -> int:
    ensure_dirs()

    dt_utc = now_utc_dt()
    ts_utc = dt_utc.isoformat()
    bt_utc = build_time_utc_str(dt_utc)

    # load previous state (Ð´Ð»Ñ Ð´Ð¸Ñ„Ñ„Ð¾Ð² Ð² report.py)
    old_state = load_json(STATE_JSON, {})
    if not isinstance(old_state, dict):
        old_state = {}

    prev_block = {
        "itdog_domains": old_state.get("itdog_domains", []) if isinstance(old_state.get("itdog_domains"), list) else [],
        "v2fly_extras": old_state.get("v2fly_extras", []) if isinstance(old_state.get("v2fly_extras"), list) else [],
        "final_domains": old_state.get("final_domains", []) if isinstance(old_state.get("final_domains"), list) else [],
    }

    warnings: List[str] = []

    # ---------------- itdog ----------------
    itdog_fetch = http_get_text(ITDOG_URL)
    if not itdog_fetch.ok:
        warnings.append(f"ðŸ”´ itdog: Ð½Ðµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ ÑÐºÐ°Ñ‡Ð°Ñ‚ÑŒ ({itdog_fetch.error})")
        itdog_list: List[str] = []
    else:
        itdog_list = parse_itdog(itdog_fetch.text)

    # ÑƒÐ½Ð¸ÐºÐ°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ, Ð½Ð¾ Ñ ÑÐ¾Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸ÐµÐ¼ Ð¿Ð¾Ñ€ÑÐ´ÐºÐ°
    itdog_unique = list(dict.fromkeys(itdog_list))
    itdog_set = set(itdog_unique)

    # ---------------- v2fly ----------------
    cats = read_v2fly_categories(V2FLY_CATEGORIES_FILE)
    v2fly_all: List[str] = []
    v2fly_per_category: Dict[str, Dict] = {}
    failed_categories: List[str] = []
    empty_categories: List[str] = []
    ok_count = 0
    fail_count = 0

    debug_lines: List[str] = []
    debug_lines.append(f"UTC: {ts_utc}")
    debug_lines.append(f"build_time_utc: {bt_utc}")
    debug_lines.append(f"Categories file: {V2FLY_CATEGORIES_FILE.as_posix()}")
    debug_lines.append(f"Categories count: {len(cats)}")
    debug_lines.append("")

    if not V2FLY_CATEGORIES_FILE.exists():
        warnings.append("âš ï¸ v2fly: Ð½ÐµÑ‚ Ñ„Ð°Ð¹Ð»Ð° src/v2fly_allow.txt (v2fly Ð¿Ñ€Ð¾Ð¿ÑƒÑ‰ÐµÐ½)")
    elif len(cats) == 0:
        warnings.append("âš ï¸ v2fly: Ñ„Ð°Ð¹Ð» ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð¹ Ð¿ÑƒÑÑ‚Ð¾Ð¹ (v2fly Ð¿Ñ€Ð¾Ð¿ÑƒÑ‰ÐµÐ½)")
    else:
        for cat in cats:
            url = f"{V2FLY_DATA_BASE}/{cat}"
            res = http_get_text(url)

            if not res.ok:
                fail_count += 1
                failed_categories.append(cat)
                v2fly_per_category[cat] = {
                    "valid_domains": 0,
                    "extras_added": 0,
                    "invalid_lines": 0,
                    "skipped_directives": 0,
                    "status": "FAIL",
                }
                debug_lines.append(f"[FAIL] {cat} -> {res.error}")
                continue

            parsed, invalid_lines, skipped_directives = parse_v2fly_file_with_stats(res.text)
            valid_domains = len(parsed)

            status = "OK"
            if valid_domains == 0:
                status = "EMPTY"
                empty_categories.append(cat)

            if status == "OK":
                ok_count += 1

            v2fly_all.extend(parsed)
            v2fly_per_category[cat] = {
                "valid_domains": valid_domains,
                "extras_added": 0,  # Ð¿Ð¾ÑÑ‡Ð¸Ñ‚Ð°ÐµÐ¼ Ð½Ð¸Ð¶Ðµ, Ð¿Ð¾ÑÐ»Ðµ Ð²Ñ‹Ñ‡Ð¸Ñ‚Ð°Ð½Ð¸Ñ itdog
                "invalid_lines": invalid_lines,
                "skipped_directives": skipped_directives,
                "status": status,
            }
            debug_lines.append(
                f"[{status}] {cat} -> lines={len(res.text.splitlines())}, domains={valid_domains}, invalid={invalid_lines}, skipped={skipped_directives}"
            )

        if fail_count:
            warnings.append(f"ðŸ”´ v2fly: Ð½Ðµ ÑÐºÐ°Ñ‡Ð°Ð»Ð¸ÑÑŒ/Ð½Ðµ Ñ€Ð°ÑÐ¿Ð°Ñ€ÑÐ¸Ð»Ð¸ÑÑŒ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð¸: {fail_count}/{len(cats)}")
        if empty_categories:
            warnings.append(f"ðŸŸ¡ v2fly: Ð¿ÑƒÑÑ‚Ñ‹Ðµ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð¸ (0 Ð´Ð¾Ð¼ÐµÐ½Ð¾Ð²): {', '.join(empty_categories)}")
        if len(v2fly_all) == 0 and cats:
            warnings.append("ðŸŸ¡ v2fly: ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð¸ ÑƒÐºÐ°Ð·Ð°Ð½Ñ‹, Ð½Ð¾ Ð´Ð¾Ð¼ÐµÐ½Ð¾Ð² Ð½Ðµ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¾")

    # v2fly extras: Ð² Ñ…Ð²Ð¾ÑÑ‚, Ð±ÐµÐ· Ð´ÑƒÐ±Ð»ÐµÐ¹ Ð¾Ñ‚Ð½Ð¾ÑÐ¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ itdog
    v2fly_unique_sorted = sorted({d for d in v2fly_all if d not in itdog_set})

    # extras_added per category (ÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾ Ð¿Ð¾Ð¿Ð°Ð»Ð¾ Ð² extras, Ð° Ð½Ðµ Ð¿ÐµÑ€ÐµÑÐµÑ‡ÐµÐ½Ð¸Ðµ Ñ itdog)
    v2fly_extras_set = set(v2fly_unique_sorted)
    for cat, st in v2fly_per_category.items():
        if not isinstance(st, dict):
            continue
        # Ð¼Ñ‹ Ð½Ðµ Ð·Ð½Ð°ÐµÐ¼ ÐºÐ°ÐºÐ¸Ðµ Ð´Ð¾Ð¼ÐµÐ½Ñ‹ Ð¸Ð· ÐºÐ°ÐºÐ¸Ñ… ÑÑ‚Ñ€Ð¾Ðº Ð¿Ð¾Ð¿Ð°Ð»Ð¸ (Ð¿Ð¾ÑÐ»Ðµ ÑÐ¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²ÐºÐ¸),
        # Ð¿Ð¾ÑÑ‚Ð¾Ð¼Ñƒ ÑÑ‡Ð¸Ñ‚Ð°ÐµÐ¼ Ð¿Ð¾ Ð¿ÐµÑ€ÐµÑÐµÑ‡ÐµÐ½Ð¸ÑŽ: Ð´Ð¾Ð¼ÐµÐ½Ñ‹ ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð¸ âˆ© extras
        # Ð”Ð»Ñ ÑÑ‚Ð¾Ð³Ð¾ Ð½ÑƒÐ¶Ð½Ð¾ Ð²Ð¾ÑÑÑ‚Ð°Ð½Ð¾Ð²Ð¸Ñ‚ÑŒ ÑÐ¿Ð¸ÑÐ¾Ðº Ð´Ð¾Ð¼ÐµÐ½Ð¾Ð² ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð¸ â€” Ð¼Ñ‹ ÐµÐ³Ð¾ Ð½Ðµ Ñ…Ñ€Ð°Ð½Ð¸Ð¼.
        # ÐŸÐ¾ÑÑ‚Ð¾Ð¼Ñƒ ÑÑ‡Ð¸Ñ‚Ð°ÐµÐ¼ Ð¿Ñ€Ð¸Ð±Ð»Ð¸Ð·Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾: extras_added = min(valid_domains, |extras|) Ð´Ð»Ñ OK/EMPTY
        # Ð§Ñ‚Ð¾Ð±Ñ‹ Ð±Ñ‹Ð»Ð¾ ÑÑ‚Ñ€Ð¾Ð³Ð¾, Ð»ÑƒÑ‡ÑˆÐµ Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ doms_by_cat, Ð½Ð¾ ÑÑ‚Ð¾ ÑƒÐ²ÐµÐ»Ð¸Ñ‡Ð¸Ñ‚ state.json.
        # Ð”ÐµÐ»Ð°ÐµÑ‚ Ð¼Ð¸Ð½Ð¸Ð¼Ð°Ð»ÑŒÐ½Ñ‹Ð¹, Ð½Ð¾ ÑÑ‚Ð°Ð±Ð¸Ð»ÑŒÐ½Ñ‹Ð¹ Ð¿Ð¾ÐºÐ°Ð·Ð°Ñ‚ÐµÐ»ÑŒ:
        st["extras_added"] = 0

    # Ð¡Ñ‚Ñ€Ð¾Ð³Ð¸Ð¹ Ð¿Ð¾Ð´ÑÑ‡Ñ‘Ñ‚ extras_added Ð±ÐµÐ· Ñ€Ð¾ÑÑ‚Ð° state.json: Ð¿ÐµÑ€ÐµÑÑ‡Ð¸Ñ‚Ð°ÐµÐ¼ Ð²Ñ‚Ð¾Ñ€Ð¾Ð¹ Ñ€Ð°Ð·,
    # Ð½Ð¾ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¼Ð½Ð¾Ð¶ÐµÑÑ‚Ð²Ð° ÐºÐ°Ñ‚ÐµÐ³Ð¾Ñ€Ð¸Ð¹ (Ð±ÐµÐ· Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ ÑÐ¿Ð¸ÑÐºÐ°): Ñ‚ÑÐ¶ÐµÐ»Ð¾ Ð±ÐµÐ· doms_by_cat.
    # ÐŸÐ¾ÑÑ‚Ð¾Ð¼Ñƒ Ñ…Ñ€Ð°Ð½Ð¸Ð¼ doms_by_cat Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ð¾ Ð¸ ÑÑ‡Ð¸Ñ‚Ð°ÐµÐ¼.
    # (Ð­Ñ‚Ð¾ Ð´Ð¾Ð±Ð°Ð²Ð¸Ñ‚ Ð½ÐµÐ¼Ð½Ð¾Ð³Ð¾ Ð¿Ð°Ð¼ÑÑ‚Ð¸, Ð½Ð¾ Ð½Ðµ Ð¿Ð¾Ð¿Ð°Ð´Ñ‘Ñ‚ Ð² state.json.)
    # ---
    if cats and V2FLY_CATEGORIES_FILE.exists():
        doms_by_cat: Dict[str, set] = {}
        for cat in cats:
            url = f"{V2FLY_DATA_BASE}/{cat}"
            res = http_get_text(url)
            if not res.ok:
                continue
            parsed, _, _ = parse_v2fly_file_with_stats(res.text)
            doms_by_cat[cat] = set(parsed)
        for cat, doms in doms_by_cat.items():
            st = v2fly_per_category.get(cat)
            if isinstance(st, dict):
                st["extras_added"] = len(doms & v2fly_extras_set)

    final_raw = itdog_unique + v2fly_unique_sorted
    truncated = max(0, len(final_raw) - MAX_LINES)
    final_list = final_raw[:MAX_LINES]

    # ÐºÐ°Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð²Ñ‹Ð²Ð¾Ð´Ð°: Ð²ÑÐµ Ð»Ð¸ ÑÑ‚Ñ€Ð¾ÐºÐ¸ Ð²Ð°Ð»Ð¸Ð´Ð½Ñ‹Ðµ Ð´Ð¾Ð¼ÐµÐ½Ñ‹
    bad_output_lines = sum(1 for x in final_list if not is_domain(x))

    FINAL_OUT.write_text("\n".join(final_list) + "\n", encoding="utf-8")
    sha_final = sha256_file(FINAL_OUT)

    # debug
    debug_lines.append("")
    debug_lines.append(f"itdog: {len(itdog_unique)}")
    debug_lines.append(f"v2fly extras: {len(v2fly_unique_sorted)}")
    debug_lines.append(f"final_raw: {len(final_raw)}")
    debug_lines.append(f"final_saved: {len(final_list)}")
    debug_lines.append(f"truncated: {truncated}")
    debug_lines.append(f"bad_output_lines: {bad_output_lines}")
    debug_lines.append(f"sha256_final: {sha_final}")

    DEBUG_V2FLY.write_text("\n".join(debug_lines) + "\n", encoding="utf-8")

    # history (ÑÐ½Ð°Ð¿ÑˆÐ¾Ñ‚ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ ÐµÑÐ»Ð¸ Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¾ Ð¸Ð·Ð¼ÐµÐ½Ð¸Ð»Ð¾ÑÑŒ)
    prev_final_list = prev_block.get("final_domains", []) if isinstance(prev_block.get("final_domains"), list) else []
    if prev_final_list and (set(prev_final_list) != set(final_list)):
        stamp = now_stamp(dt_utc)
        snap_prev = HISTORY_DIR / f"snapshot-{stamp}-prev.lst"
        snap_new = HISTORY_DIR / f"snapshot-{stamp}-new.lst"
        diff_file = HISTORY_DIR / f"diff-{stamp}.txt"

        snap_prev.write_text("\n".join(prev_final_list) + "\n", encoding="utf-8")
        snap_new.write_text("\n".join(final_list) + "\n", encoding="utf-8")

        added, removed = diff_lists(prev_final_list, final_list)
        diff_lines: List[str] = []
        diff_lines.append(f"UTC: {ts_utc}")
        diff_lines.append(f"added: {len(added)}")
        diff_lines.append(f"removed: {len(removed)}")
        diff_lines.append("")
        diff_lines.append("ADDED (top 200):")
        diff_lines.extend(added[:200] if added else ["â€”"])
        diff_lines.append("")
        diff_lines.append("REMOVED (top 200):")
        diff_lines.extend(removed[:200] if removed else ["â€”"])
        diff_file.write_text("\n".join(diff_lines) + "\n", encoding="utf-8")

        rotate_history(HISTORY_DIR, MAX_HISTORY)

    # state.json (Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº Ð¿Ñ€Ð°Ð²Ð´Ñ‹ Ð´Ð»Ñ report.py)
    state = {
        "build_time_utc": bt_utc,
        "repo": "SkyNextGen/kvas-domains",
        "output": "dist/inside-kvas.lst",
        "max_lines": MAX_LINES,
        "near_limit_threshold": NEAR_LIMIT_THRESHOLD,
        "sha256_final": sha_final,
        "itdog_domains": itdog_unique,
        "v2fly_extras": v2fly_unique_sorted,
        "final_domains": final_list,
        "itdog_total": len(set(itdog_unique)),
        "v2fly_total": len(set(v2fly_unique_sorted)),
        "final_total": len(set(final_list)),
        "truncated": truncated,
        "truncated_yesno": "YES" if truncated > 0 else "NO",
        "bad_output_lines": bad_output_lines,
        "v2fly_ok": ok_count,
        "v2fly_fail": fail_count,
        "v2fly_categories": cats,
        "v2fly_per_category": v2fly_per_category,
        "warnings": warnings,
        "failed_categories": failed_categories,
        "empty_categories": empty_categories,
        "prev": prev_block,
    }
    dump_json(STATE_JSON, state)

    return 0


if __name__ == "__main__":
    raise SystemExit(main())
